"""
Vietnamese Text Processor for HaUI Chatbot
Handles spell checking, abbreviation expansion, and text normalization.
Optimized for educational domain (SICT/HaUI context).
"""

import re
import unicodedata
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class VietnameseTextProcessor:
    """
    Xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t:
    - Sá»­a lá»—i chÃ­nh táº£ thÃ´ng dá»¥ng
    - Má»Ÿ rá»™ng tá»« viáº¿t táº¯t
    - Chuáº©n hÃ³a Unicode
    - Xá»­ lÃ½ tá»« lÃ³ng giá»›i tráº»
    """
    
    # === Tá»ª VIáº¾T Táº®T PHá»” BIáº¾N ===
    ABBREVIATIONS: Dict[str, str] = {
        # GiÃ¡o dá»¥c
        "sv": "sinh viÃªn",
        "gv": "giáº£ng viÃªn",
        "ths": "tháº¡c sÄ©",
        "ts": "tiáº¿n sÄ©",
        "pgs": "phÃ³ giÃ¡o sÆ°",
        "gs": "giÃ¡o sÆ°",
        "cn": "cá»­ nhÃ¢n",
        "ks": "ká»¹ sÆ°",
        "Ä‘h": "Ä‘áº¡i há»c",
        "cÄ‘": "cao Ä‘áº³ng",
        "tc": "trung cáº¥p",
        "hv": "há»c viÃªn",
        "hvch": "há»c viÃªn cao há»c",
        "ncs": "nghiÃªn cá»©u sinh",
        "Ä‘atn": "Ä‘á»“ Ã¡n tá»‘t nghiá»‡p",
        "kltn": "khÃ³a luáº­n tá»‘t nghiá»‡p",
        "Ä‘amh": "Ä‘á»“ Ã¡n mÃ´n há»c",
        "btl": "bÃ i táº­p lá»›n",
        "gpa": "Ä‘iá»ƒm trung bÃ¬nh tÃ­ch lÅ©y",
        
        # NgÃ nh há»c
        "cntt": "cÃ´ng nghá»‡ thÃ´ng tin",
        "khmt": "khoa há»c mÃ¡y tÃ­nh",
        "ktpm": "ká»¹ thuáº­t pháº§n má»m",
        "httt": "há»‡ thá»‘ng thÃ´ng tin",
        "attt": "an toÃ n thÃ´ng tin",
        "ttnt": "trÃ­ tuá»‡ nhÃ¢n táº¡o",
        "ai": "trÃ­ tuá»‡ nhÃ¢n táº¡o",
        "ml": "há»c mÃ¡y",
        "dl": "há»c sÃ¢u",
        "iot": "internet váº¡n váº­t",
        "cnÄ‘pt": "cÃ´ng nghá»‡ Ä‘a phÆ°Æ¡ng tiá»‡n",
        "Ä‘tvt": "Ä‘iá»‡n tá»­ viá»…n thÃ´ng",
        "cÆ¡Ä‘t": "cÆ¡ Ä‘iá»‡n tá»­",
        "ktÄ‘k": "ká»¹ thuáº­t Ä‘iá»u khiá»ƒn",
        
        # TrÆ°á»ng/Khoa
        "haui": "Ä‘áº¡i há»c cÃ´ng nghiá»‡p hÃ  ná»™i",
        "sict": "trÆ°á»ng cÃ´ng nghá»‡ thÃ´ng tin vÃ  truyá»n thÃ´ng",
        "dhcnhn": "Ä‘áº¡i há»c cÃ´ng nghiá»‡p hÃ  ná»™i",
        "bct": "bá»™ cÃ´ng thÆ°Æ¡ng",
        
        # HÃ nh chÃ­nh
        "hp": "há»c pháº§n",
        "tc": "tÃ­n chá»‰",
        "hk": "há»c ká»³",
        "nh": "nÄƒm há»c",
        "ctÄ‘t": "chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o",
        "Ä‘cv": "Ä‘iá»ƒm chuáº©n vÃ o",
        "xl": "xÃ©t láº¡i",
        "hp2": "há»c pháº§n 2",
        "tkb": "thá»i khÃ³a biá»ƒu",
        "lhp": "lá»‹ch há»c pháº§n",
        "Ä‘khp": "Ä‘Äƒng kÃ½ há»c pháº§n",
        "clb": "cÃ¢u láº¡c bá»™",
        "Ä‘tn": "Ä‘oÃ n thanh niÃªn",
        "hsv": "há»™i sinh viÃªn",
        
        # ThÃ´ng dá»¥ng
        "nt": "nháº¯n tin",
        "sÄ‘t": "sá»‘ Ä‘iá»‡n thoáº¡i",
        "Ä‘c": "Ä‘á»‹a chá»‰",
        "hcm": "há»“ chÃ­ minh",
        "hn": "hÃ  ná»™i",
        "tphcm": "thÃ nh phá»‘ há»“ chÃ­ minh",
        "vn": "viá»‡t nam",
        "tn": "thá»© nÄƒm",
        "t2": "thá»© hai",
        "t3": "thá»© ba",
        "t4": "thá»© tÆ°",
        "t5": "thá»© nÄƒm",
        "t6": "thá»© sÃ¡u",
        "t7": "thá»© báº£y",
        "cn": "chá»§ nháº­t",
        
        # Tá»« viáº¿t táº¯t internet
        "dc": "Ä‘Æ°á»£c",
        "ko": "khÃ´ng",
        "k": "khÃ´ng",
        "hok": "há»c",
        "thi": "thi",
        "bt": "bÃ¬nh thÆ°á»ng",
        "ntn": "nhÆ° tháº¿ nÃ o",
        "cx": "cÅ©ng",
        "vs": "vá»›i",
        "j": "gÃ¬",
        "z": "váº­y",
        "r": "rá»“i",
        "lm": "lÃ m",
        "ns": "nÃ³i",
        "Ä‘c": "Ä‘Æ°á»£c",
        "Ä‘ag": "Ä‘ang",
        "mk": "mÃ¬nh",
        "bn": "báº¡n",
        "trc": "trÆ°á»›c",
        "sau": "sau",
    }
    
    # === Lá»–I CHÃNH Táº¢ THÃ”NG Dá»¤NG ===
    COMMON_TYPOS: Dict[str, str] = {
        # Lá»—i dáº¥u
        "cÃ´ng nghe": "cÃ´ng nghá»‡",
        "thÃ´ng tinh": "thÃ´ng tin",
        "Ä‘ai há»c": "Ä‘áº¡i há»c",
        "nganh": "ngÃ nh",
        "truong": "trÆ°á»ng",
        "sinh vien": "sinh viÃªn",
        "giang vien": "giáº£ng viÃªn",
        "hoc phi": "há»c phÃ­",
        "tuyen sinh": "tuyá»ƒn sinh",
        "dao tao": "Ä‘Ã o táº¡o",
        "chuong trinh": "chÆ°Æ¡ng trÃ¬nh",
        "ky thuat": "ká»¹ thuáº­t",
        "phan mem": "pháº§n má»m",
        "he thong": "há»‡ thá»‘ng",
        "an toan": "an toÃ n",
        "may tinh": "mÃ¡y tÃ­nh",
        "khoa hoc": "khoa há»c",
        "cong nghiep": "cÃ´ng nghiá»‡p",
        "ha noi": "hÃ  ná»™i",
        
        # Lá»—i phá»¥ Ã¢m
        "cÃ´ng ngá»‡": "cÃ´ng nghá»‡",
        "thÃ´g tin": "thÃ´ng tin",
        "sihn viÃªn": "sinh viÃªn",
        "giáº£n viÃªn": "giáº£ng viÃªn",
        
        # Lá»—i nguyÃªn Ã¢m
        "cuÃ´ng nghá»‡": "cÃ´ng nghá»‡",
        "thung tin": "thÃ´ng tin",
        "Ä‘oÃ  táº¡o": "Ä‘Ã o táº¡o",
        
        # Lá»—i viáº¿t liá»n
        "cÃ´ngnghá»‡": "cÃ´ng nghá»‡",
        "thÃ´ngtin": "thÃ´ng tin",
        "sinhviÃªn": "sinh viÃªn",
        "Ä‘áº¡ihá»c": "Ä‘áº¡i há»c",
        "há»cphÃ­": "há»c phÃ­",
        
        # Domain-specific
        "cntt": "cÃ´ng nghá»‡ thÃ´ng tin",  # ÄÃ£ cÃ³ trong abbreviations nhÆ°ng giá»¯ Ä‘á»ƒ backup
    }
    
    # === Tá»ª LÃ“NG GIá»šI TRáºº ===
    SLANG_WORDS: Dict[str, str] = {
        "Ã´kÃª": "Ä‘Æ°á»£c",
        "ok": "Ä‘Æ°á»£c",
        "okie": "Ä‘Æ°á»£c",
        "okela": "Ä‘Æ°á»£c",
        "oke": "Ä‘Æ°á»£c",
        "noob": "ngÆ°á»i má»›i",
        "pro": "chuyÃªn nghiá»‡p",
        "fix": "sá»­a",
        "bug": "lá»—i",
        "deadline": "háº¡n ná»™p",
        "submit": "ná»™p bÃ i",
        "review": "Ä‘Ã¡nh giÃ¡",
        "pass": "Ä‘á»—",
        "fail": "trÆ°á»£t",
        "gpa": "Ä‘iá»ƒm trung bÃ¬nh",
        "gap year": "nÄƒm nghá»‰",
        "intern": "thá»±c táº­p",
        "offer": "Ä‘á» nghá»‹ lÃ m viá»‡c",
    }
    
    def __init__(self, enable_typo_fix: bool = True, enable_abbrev: bool = True):
        """
        Khá»Ÿi táº¡o text processor.
        
        Args:
            enable_typo_fix: Báº­t/táº¯t sá»­a lá»—i chÃ­nh táº£
            enable_abbrev: Báº­t/táº¯t má»Ÿ rá»™ng tá»« viáº¿t táº¯t
        """
        self.enable_typo_fix = enable_typo_fix
        self.enable_abbrev = enable_abbrev
        
        # Compile regex patterns for efficiency
        self._compile_patterns()
    
    def _compile_patterns(self):
        """Compile regex patterns for faster matching."""
        # Pattern for abbreviations (word boundaries)
        abbrev_pattern = r'\b(' + '|'.join(
            re.escape(k) for k in sorted(self.ABBREVIATIONS.keys(), key=len, reverse=True)
        ) + r')\b'
        self._abbrev_regex = re.compile(abbrev_pattern, re.IGNORECASE)
        
        # Pattern for slang
        slang_pattern = r'\b(' + '|'.join(
            re.escape(k) for k in sorted(self.SLANG_WORDS.keys(), key=len, reverse=True)
        ) + r')\b'
        self._slang_regex = re.compile(slang_pattern, re.IGNORECASE)
    
    def normalize_unicode(self, text: str) -> str:
        """
        Chuáº©n hÃ³a Unicode (NFC normalization).
        Äáº£m báº£o cÃ¡c kÃ½ tá»± tiáº¿ng Viá»‡t Ä‘Æ°á»£c biá»ƒu diá»…n nháº¥t quÃ¡n.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            VÄƒn báº£n Ä‘Ã£ chuáº©n hÃ³a
        """
        return unicodedata.normalize('NFC', text)
    
    def expand_abbreviations(self, text: str) -> str:
        """
        Má»Ÿ rá»™ng tá»« viáº¿t táº¯t thÃ nh tá»« Ä‘áº§y Ä‘á»§.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            VÄƒn báº£n Ä‘Ã£ má»Ÿ rá»™ng tá»« viáº¿t táº¯t
        """
        if not self.enable_abbrev:
            return text
        
        def replace_abbrev(match):
            abbrev = match.group(1).lower()
            return self.ABBREVIATIONS.get(abbrev, match.group(0))
        
        return self._abbrev_regex.sub(replace_abbrev, text)
    
    def fix_typos(self, text: str) -> str:
        """
        Sá»­a lá»—i chÃ­nh táº£ thÃ´ng dá»¥ng.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            VÄƒn báº£n Ä‘Ã£ sá»­a lá»—i
        """
        if not self.enable_typo_fix:
            return text
        
        result = text.lower()
        for typo, correct in self.COMMON_TYPOS.items():
            # Case-insensitive replacement
            pattern = re.compile(re.escape(typo), re.IGNORECASE)
            result = pattern.sub(correct, result)
        
        return result
    
    def replace_slang(self, text: str) -> str:
        """
        Thay tháº¿ tá»« lÃ³ng báº±ng tá»« chuáº©n.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            VÄƒn báº£n Ä‘Ã£ thay tháº¿ tá»« lÃ³ng
        """
        def replace_slang_word(match):
            slang = match.group(1).lower()
            return self.SLANG_WORDS.get(slang, match.group(0))
        
        return self._slang_regex.sub(replace_slang_word, text)
    
    def clean_whitespace(self, text: str) -> str:
        """
        Chuáº©n hÃ³a khoáº£ng tráº¯ng.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            VÄƒn báº£n Ä‘Ã£ chuáº©n hÃ³a khoáº£ng tráº¯ng
        """
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text)
        # Remove whitespace around punctuation
        text = re.sub(r'\s+([,.!?;:])', r'\1', text)
        return text.strip()
    
    def process(self, text: str) -> Tuple[str, Dict[str, any]]:
        """
        Xá»­ lÃ½ toÃ n bá»™ vÄƒn báº£n qua táº¥t cáº£ cÃ¡c bÆ°á»›c.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            Tuple gá»“m (vÄƒn báº£n Ä‘Ã£ xá»­ lÃ½, metadata vá» cÃ¡c thay Ä‘á»•i)
        """
        original = text
        changes = {
            "original": original,
            "abbreviations_expanded": [],
            "typos_fixed": [],
            "slang_replaced": [],
        }
        
        # Step 1: Normalize Unicode
        text = self.normalize_unicode(text)
        
        # Step 2: Expand abbreviations
        before_abbrev = text
        text = self.expand_abbreviations(text)
        if before_abbrev != text:
            changes["abbreviations_expanded"].append({
                "before": before_abbrev,
                "after": text
            })
        
        # Step 3: Fix typos
        before_typo = text
        text = self.fix_typos(text)
        if before_typo.lower() != text.lower():
            changes["typos_fixed"].append({
                "before": before_typo,
                "after": text
            })
        
        # Step 4: Replace slang
        before_slang = text
        text = self.replace_slang(text)
        if before_slang.lower() != text.lower():
            changes["slang_replaced"].append({
                "before": before_slang,
                "after": text
            })
        
        # Step 5: Clean whitespace
        text = self.clean_whitespace(text)
        
        changes["processed"] = text
        changes["was_modified"] = original.lower() != text.lower()
        
        return text, changes
    
    def process_simple(self, text: str) -> str:
        """
        Xá»­ lÃ½ vÄƒn báº£n Ä‘Æ¡n giáº£n, chá»‰ tráº£ vá» káº¿t quáº£.
        
        Args:
            text: VÄƒn báº£n Ä‘áº§u vÃ o
            
        Returns:
            VÄƒn báº£n Ä‘Ã£ xá»­ lÃ½
        """
        processed, _ = self.process(text)
        return processed


# === SINGLETON INSTANCE ===
_processor_instance: Optional[VietnameseTextProcessor] = None

def get_text_processor() -> VietnameseTextProcessor:
    """Get or create the singleton text processor instance."""
    global _processor_instance
    if _processor_instance is None:
        _processor_instance = VietnameseTextProcessor()
    return _processor_instance


def process_query(query: str) -> str:
    """
    Convenient function to process a query.
    
    Args:
        query: User's raw query
        
    Returns:
        Processed query ready for RAG
    """
    processor = get_text_processor()
    return processor.process_simple(query)


# === TEST ===
if __name__ == "__main__":
    processor = VietnameseTextProcessor()
    
    test_cases = [
        "CNTT lÃ  gÃ¬?",
        "Há»c phÃ­ SV nÄƒm 2025 lÃ  bao nhiÃªu?",
        "SICT cÃ³ nhá»¯ng ngÃ nh nÃ o?",
        "cÃ´ng nghe thÃ´ng tinh há»c j?",
        "deadline Ä‘Äƒng kÃ½ há»c pháº§n khi nÃ o?",
        "GV hÆ°á»›ng dáº«n ÄATN lÃ  ai?",
        "cho mk há»i HTTT vs KTPM khÃ¡c j nhau?",
        "haui á»Ÿ Ä‘Ã¢u z bn?",
    ]
    
    print("=" * 60)
    print("Vietnamese Text Processor - Test Cases")
    print("=" * 60)
    
    for query in test_cases:
        processed, changes = processor.process(query)
        print(f"\nğŸ“ Input:  {query}")
        print(f"âœ… Output: {processed}")
        if changes["was_modified"]:
            print(f"   [Modified]")
